# -*- coding: utf-8 -*-
"""Spam_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RXYzmQbjp5x1Iryxb3hJukI50LCSmRhA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score

dataset=pd.read_csv('/content/emails_2.csv')
dataset.head()

dataset.info()

dataset['spam'].value_counts()

dataset[dataset['spam']==0]

dataset[dataset['spam']==1]

dataset.isnull().sum()
dataset=dataset.drop_duplicates()

plt.pie(dataset['spam'].value_counts(),labels=['Ham','Spam'],autopct='%0.2f')
plt.show()

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')

dataset['char_num']=dataset['text'].apply(len)
dataset.head(10)

dataset['words_num']=dataset['text'].apply(lambda x:len(nltk.word_tokenize(x)))
dataset.head(10)

plt.figure(figsize=(20,6))
sns.histplot(dataset[dataset['spam']==0]['char_num'],color='mediumseagreen')
sns.histplot(dataset[dataset['spam']==1]['char_num'],color='red')
#plt.legend(['Ham','Spam'])

plt.figure(figsize=(20,6))
sns.histplot(dataset[dataset['spam']==0]['words_num'],color='mediumseagreen')
sns.histplot(dataset[dataset['spam']==1]['words_num'],color='red')

vectorizer=CountVectorizer()
X=vectorizer.fit_transform(dataset['text'])

X_trian,X_test,y_train,y_test=train_test_split(X,dataset['spam'],test_size=0.2)

model=MultinomialNB()
model.fit(X_trian,y_train)

y_pred=model.predict(X_test)
acc=accuracy_score(y_test,y_pred)
print(acc)

model_2=BernoulliNB()
model_2.fit(X_trian,y_train)

y_pred1=model_2.predict(X_test)
acc1=accuracy_score(y_test,y_pred1)
print(acc1)

model_1=GaussianNB()
model_1.fit(X_trian.toarray(),y_train)

y_pred2=model_1.predict(X_test.toarray())
acc2=accuracy_score(y_test,y_pred2)
print(acc2)

#gaussianNB()
def predictMessage(message):
  messageVector=vectorizer.transform([message])
  prediction=model_1.predict(messageVector.toarray())
  return "Spam" if prediction[0]==1 else "Ham"

usermsg=input("Enter your Message:")
predict=predictMessage(usermsg)
print(f'The message is :{predict}')

#MultinomialNb() >>>>>>>>>>>>> combine of gaussianNb() And BernoulliNB()
def predictMessage(message):
  messageVector=vectorizer.transform([message])
  prediction=model.predict(messageVector)
  return "Spam" if prediction[0]==1 else "Ham"

usermsg=input("Enter your Message:")
predict=predictMessage(usermsg)
print(f'The message is :{predict}')

#BernoulliNb()
def predictMessage(message):
  messageVector=vectorizer.transform([message])
  prediction=model_2.predict(messageVector.toarray())
  return "Spam" if prediction[0]==1 else "Ham"

usermsg=input("Enter your Message:")
predict=predictMessage(usermsg)
print(f'The message is :{predict}')